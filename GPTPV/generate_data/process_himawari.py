import xarray as xr
import numpy as np
import pandas as pd
import os
import glob
from tqdm import tqdm
from GPTPV.utils.config import load_config


# ===========================================

def get_spatial_indices(sample_file):
    """
    åªè¿è¡Œä¸€æ¬¡ï¼šè®¡ç®— "å“ªäº›åƒç´ ç‚¹" æ˜¯æˆ‘ä»¬éœ€è¦æå–çš„ã€‚
    è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å« 100 ä¸ª (lat_idx, lon_idx) åæ ‡å¯¹ä»¥åŠç»çº¬åº¦æ•°å€¼ã€‚
    """
    print(f"ğŸŒ æ­£åœ¨è®¡ç®—ç©ºé—´ç´¢å¼•ï¼Œä½¿ç”¨æ¨¡æ¿æ–‡ä»¶: {sample_file}")
    ds = xr.open_dataset(sample_file)

    lats = ds['latitude'].values
    lons = ds['longitude'].values

    # ç”Ÿæˆç½‘æ ¼åæ ‡çŸ©é˜µ
    lon_grid, lat_grid = np.meshgrid(lons, lats)

    all_selected_indices = []

    for station in REAL_STATIONS:
        # è®¡ç®—è¯¥ç”µç«™åˆ°æ‰€æœ‰åƒç´ ç‚¹çš„è·ç¦»å¹³æ–¹ (æ¬§æ°è·ç¦»è¿‘ä¼¼)
        dist_sq = (lat_grid - station['lat']) ** 2 + (lon_grid - station['lon']) ** 2

        # æ‰¾åˆ°è·ç¦»æœ€è¿‘çš„ N ä¸ªç‚¹
        flat_indices = np.argpartition(dist_sq.ravel(), POINTS_PER_STATION)[:POINTS_PER_STATION]
        y_indices, x_indices = np.unravel_index(flat_indices, dist_sq.shape)

        for y, x in zip(y_indices, x_indices):
            all_selected_indices.append({
                "station": station['name'],
                "lat_val": float(lats[y]),  # ç¡®ä¿è½¬æ¢ä¸ºpython float
                "lon_val": float(lons[x]),
                "lat_idx": y,
                "lon_idx": x
            })

    print(f"âœ… ç©ºé—´é€‰ç‚¹å®Œæˆï¼å…±é€‰ä¸­ {len(all_selected_indices)} ä¸ªè™šæ‹Ÿç«™ç‚¹ã€‚")
    return all_selected_indices


def save_station_coordinates(indices_list, save_path):
    """
    æ–°å¢åŠŸèƒ½ï¼šå°†ç­›é€‰å‡ºçš„è™šæ‹Ÿç«™ç‚¹ç»çº¬åº¦ä¿å­˜ä¸º CSV
    """
    print(f"ğŸ’¾ æ­£åœ¨ä¿å­˜è™šæ‹Ÿç«™ç‚¹åæ ‡è‡³: {save_path}")

    coord_data = []

    # éå†åˆ—è¡¨ï¼Œæ„é€ ä¸ process_temporal_data ä¸­å®Œå…¨ä¸€è‡´çš„ Station ID
    for i, info in enumerate(indices_list):
        # è¿™é‡Œçš„å‘½åé€»è¾‘å¿…é¡»ä¸ä¸‹é¢å¤„ç†æ—¶é—´åºåˆ—æ—¶çš„é€»è¾‘ä¿æŒä¸€è‡´ï¼šStationName_P{0...19}
        station_id = f"{info['station']}_P{i % POINTS_PER_STATION}"

        coord_data.append({
            "Station_ID": station_id,
            "Real_Station_Ref": info['station'],  # å½’å±çš„çœŸå®ç”µç«™
            "Latitude": info['lat_val'],
            "Longitude": info['lon_val']
        })

    df_coords = pd.DataFrame(coord_data)
    df_coords.to_csv(save_path, index=False)
    print(f"âœ… åæ ‡ä¿å­˜æˆåŠŸï¼")


def process_temporal_data(target_indices, date_list):
    """
    éå†æ¯ä¸€å¤©ã€æ¯ä¸ªæ–‡ä»¶ï¼Œæå– SWR æ•°æ®
    """
    results = []

    for current_date in date_list:
        date_str = current_date.strftime("%Y-%m-%d")
        yyyy = current_date.strftime("%Y")
        mm = current_date.strftime("%m")
        dd = current_date.strftime("%d")

        print(f"\nğŸ“… æ­£åœ¨æå–æ•°æ®: {date_str}")

        time_mapping = {
            "00": "00",
            "20": "15",
            "30": "30",
            "50": "45"
        }

        for hour in tqdm(range(24), desc="Hour Loop"):
            hh = f"{hour:02d}"
            hour_dir = os.path.join(DATA_DIR, f"{yyyy}{mm}", dd, hh)

            if not os.path.exists(hour_dir):
                continue

            files = sorted(os.listdir(hour_dir))

            for f_name in files:
                if not f_name.endswith(".nc") or "02401_02401" not in f_name:
                    continue

                try:
                    time_part = f_name.split("_")[2]
                    minute_str = time_part[2:]
                except:
                    continue

                if minute_str not in time_mapping:
                    continue

                target_minute = time_mapping[minute_str]

                full_path = os.path.join(hour_dir, f_name)
                try:
                    ds = xr.open_dataset(full_path)
                    swr_data = ds['SWR'].values
                    timestamp = pd.Timestamp(f"{date_str} {hh}:{target_minute}:00")
                    row_data = {"Timestamp": timestamp}

                    for i, idx_info in enumerate(target_indices):
                        val = swr_data[idx_info['lat_idx'], idx_info['lon_idx']]
                        if np.isnan(val) or val < 0:
                            val = 0.0

                        # å‘½ååˆ—å: Station_1_P0 (é€»è¾‘å¿…é¡»ä¸ save_station_coordinates ä¸€è‡´)
                        col_name = f"{idx_info['station']}_P{i % POINTS_PER_STATION}"
                        row_data[col_name] = val

                    results.append(row_data)
                    ds.close()

                except Exception as e:
                    print(f"è¯»å–é”™è¯¯ {f_name}: {e}")

    return pd.DataFrame(results)


def main(config):
    # 1. æ‰¾æ ·æ¿æ–‡ä»¶
    sample_files = glob.glob(f"{DATA_DIR}/*/*/*/*.nc")
    if not sample_files:
        print("âŒ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .nc æ–‡ä»¶ï¼")
        return

    valid_sample = None
    for f in sample_files:
        if "02401_02401" in f:
            valid_sample = f
            break

    if not valid_sample:
        print("âŒ æ²¡æ‰¾åˆ° 02401_02401 è§„æ ¼çš„æ–‡ä»¶ï¼")
        return

    # 2. è®¡ç®—ç©ºé—´ç´¢å¼•
    spatial_indices = get_spatial_indices(valid_sample)

    # --- æ–°å¢æ­¥éª¤ï¼šä¿å­˜ç»çº¬åº¦ ---
    save_station_coordinates(spatial_indices, coord_output_file)
    # -------------------------

    # 3. å¤„ç†æ—¶é—´åºåˆ—
    dates = pd.date_range(START_DATE, END_DATE)
    df = process_temporal_data(spatial_indices, dates)

    # 4. æ’åºå’Œä¿å­˜æ•°æ®
    if not df.empty:
        df = df.sort_values("Timestamp").set_index("Timestamp")
        df = df.bfill()

        print("\n===== æ•°æ®é¢„è§ˆ =====")
        print(df.head())

        df.to_csv(output_file)
        print(f"\nâœ… SWRæ•°æ®å¤„ç†å®Œæˆï¼å·²ä¿å­˜è‡³: {output_file}")
    else:
        print("âš ï¸ æ²¡æœ‰æå–åˆ°ä»»ä½•æ•°æ®ã€‚")


if __name__ == "__main__":
    config_file = "../config/config.yaml"
    config = load_config(config_file)

    DATA_DIR = config["file_paths"]["himawari_dir"]
    output_file = config["file_paths"]["himawari_output"]

    # æ–°å¢ï¼šå®šä¹‰åæ ‡ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    coord_output_file = config["file_paths"]["output_coord_csv"]

    # 2. æ¨¡æ‹Ÿè®ºæ–‡ä¸­çš„ "5ä¸ªçœŸå®ç”µç«™" åæ ‡
    REAL_STATIONS = config["stations"]["real_stations"]

    # 3. æ¯ä¸ªç”µç«™é€‰å¤šå°‘ä¸ªè™šæ‹Ÿç‚¹ï¼Ÿ
    POINTS_PER_STATION = config["stations"]["virtual_points_per_station"]

    # 4. è¦å¤„ç†çš„æ—¥æœŸèŒƒå›´
    START_DATE = config["dates"]["start_date"]
    END_DATE = config["dates"]["end_date"]

    main(config)
