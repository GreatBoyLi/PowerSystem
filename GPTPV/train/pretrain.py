import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from tqdm import tqdm
import matplotlib.pyplot as plt  # å¯¼å…¥ç»˜å›¾åº“

from GPTPV.model.dataset import PVForecastDataset
from GPTPV.model.model import PVGPT
from GPTPV.utils.config import load_config

import os

# åœ¨ä»£ç å¼€å¤´è®¾ç½®ï¼ŒæŒ‡å®šç¬¬3å¼ æ˜¾å¡
os.environ["CUDA_VISIBLE_DEVICES"] = "3"

# --- é…ç½® ---
config_file = "../config/config.yaml"
config = load_config(config_file)
CSV_PATH = config["file_paths"]["output_power_csv"]
weights_dir = config["file_paths"]["weights_dir"]
weights_name = "best_pretrained_model.pth"
MODEL_SAVE_PATH = os.path.join(weights_dir, weights_name)

# è¶…å‚æ•°
BATCH_SIZE = 1024
LR = 0.00005
EPOCHS = 20


def plot_loss_curve(train_losses, val_losses):
    """ç”»å‡ºè®­ç»ƒå’ŒéªŒè¯çš„ Loss æ›²çº¿"""
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='Train Loss', color='blue')
    plt.plot(val_losses, label='Validation Loss', color='orange')
    plt.xlabel('Epochs')
    plt.ylabel('MSE Loss')
    plt.title('Training and Validation Loss Curve')
    plt.legend()
    plt.grid(True)
    plt.savefig('training_loss_curve.png')  # ä¿å­˜å›¾åƒ
    print("ğŸ“‰ Loss æ›²çº¿å·²ä¿å­˜è‡³ training_loss_curve.png")
    plt.close()


def plot_validation_results(model, val_loader, device):
    """ç”»å‡ºéªŒè¯é›†çš„é¢„æµ‹å¯¹æ¯”å›¾ (éšæœºå–4ä¸ªæ ·æœ¬)"""
    model.eval()

    # è·å–ä¸€ä¸ª Batch çš„æ•°æ®
    batch = next(iter(val_loader))
    x_seq = batch['x_seq'].to(device)
    y_seq = batch['y_seq'].to(device)
    x_time = batch['x_time'].to(device)
    y_time = batch['y_time'].to(device)

    tgt_input = torch.zeros_like(y_seq).to(device)

    with torch.no_grad():
        # é¢„æµ‹
        pred = model(x_seq, tgt_input, x_time, y_time)

    # è½¬å› CPU æ–¹ä¾¿ç”»å›¾
    y_true = y_seq.cpu().numpy()
    y_pred = pred.cpu().numpy()

    # ç”»å›¾ (ç”»4ä¸ªå­å›¾å±•ç¤ºä¸åŒæ ·æœ¬)
    plt.figure(figsize=(15, 10))
    for i in range(4):  # å±•ç¤º Batch ä¸­çš„å‰4ä¸ªæ ·æœ¬
        plt.subplot(2, 2, i + 1)

        # y_true[i] shape is (16, 1), flatten to (16,)
        plt.plot(y_true[i].flatten(), label='Ground Truth', marker='o', color='green')
        plt.plot(y_pred[i].flatten(), label='Prediction', marker='x', color='red', linestyle='--')

        plt.title(f'Validation Sample {i + 1}')
        plt.xlabel('Time Steps (Future 4 hours)')
        plt.ylabel('Normalized Power')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.savefig('validation_results.png')
    print("ğŸ–¼ï¸ éªŒè¯é›†é¢„æµ‹å¯¹æ¯”å›¾å·²ä¿å­˜è‡³ validation_results.png")
    plt.close()


def train():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸš€ Using device: {device}")

    # 1. å‡†å¤‡æ•°æ®
    train_ds = PVForecastDataset(CSV_PATH, mode='train', train_ratio=0.8)
    val_ds = PVForecastDataset(CSV_PATH, mode='val', train_ratio=0.8)

    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)
    # éªŒè¯é›† shuffle=True æ˜¯ä¸ºäº†ç”»å›¾æ—¶èƒ½éšæœºçœ‹åˆ°ä¸åŒçš„æ ·æœ¬ï¼Œä¸å½±å“éªŒè¯æŒ‡æ ‡
    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)

    # 2. åˆå§‹åŒ–æ¨¡å‹
    # model = PVGPT(d_model=512, nhead=8, num_encoder_layers=3, num_decoder_layers=3, dropout=0.3).to(device)
    # æ¨¡å‹å·²ç»è¿‡æ‹Ÿåˆï¼ŒæŠŠæ¨¡å‹çš„å‚æ•°å‡å°‘ å°è¯• d_model=64 æˆ– 128
    model = PVGPT(d_model=28, nhead=4, num_encoder_layers=1, num_decoder_layers=1, dropout=0.3).to(device)  # å‚æ•°1

    # model = PVGPT(d_model=32, nhead=4, num_encoder_layers=1, num_decoder_layers=1, dropout=0.3).to(device)  # å‚æ•°2
    #
    # model = PVGPT(d_model=64, nhead=4, num_encoder_layers=2, num_decoder_layers=2, dropout=0.3).to(device)  # å‚æ•°3
    #
    # model = PVGPT(d_model=256, nhead=8, num_encoder_layers=2, num_decoder_layers=2, dropout=0.3).to(device)  # å‚æ•°4

    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=LR)

    best_val_loss = float('inf')

    # --- æ–°å¢ï¼šè®°å½•æ¯ä¸ª epoch çš„ loss ---
    train_loss_history = []
    val_loss_history = []

    # 3. è®­ç»ƒå¾ªç¯
    for epoch in range(EPOCHS):
        model.train()
        total_train_loss = 0
        loop = tqdm(train_loader, desc=f"Epoch {epoch + 1}/{EPOCHS} [Train]")

        for batch in loop:
            x_seq = batch['x_seq'].to(device)
            y_seq = batch['y_seq'].to(device)
            x_time = batch['x_time'].to(device)
            y_time = batch['y_time'].to(device)

            tgt_input = torch.zeros_like(y_seq).to(device)

            optimizer.zero_grad()
            output = model(x_seq, tgt_input, x_time, y_time)
            loss = criterion(output, y_seq)
            loss.backward()
            optimizer.step()

            total_train_loss += loss.item()
            loop.set_postfix(loss=loss.item())

        avg_train_loss = total_train_loss / len(train_loader)

        # 4. éªŒè¯å¾ªç¯
        model.eval()
        total_val_loss = 0
        with torch.no_grad():
            for batch in val_loader:
                x_seq = batch['x_seq'].to(device)
                y_seq = batch['y_seq'].to(device)
                x_time = batch['x_time'].to(device)
                y_time = batch['y_time'].to(device)

                tgt_input = torch.zeros_like(y_seq).to(device)

                output = model(x_seq, tgt_input, x_time, y_time)
                loss = criterion(output, y_seq)
                total_val_loss += loss.item()

        avg_val_loss = total_val_loss / len(val_loader)

        # --- è®°å½• Loss ---
        train_loss_history.append(avg_train_loss)
        val_loss_history.append(avg_val_loss)

        print(f"Epoch {epoch + 1} | Train Loss: {avg_train_loss:.6f} | Val Loss: {avg_val_loss:.6f}")

        # 5. ä¿å­˜æœ€ä½³æ¨¡å‹
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), MODEL_SAVE_PATH)
            print(f"ğŸ’¾ Model saved to {MODEL_SAVE_PATH}")

    # --- è®­ç»ƒç»“æŸåï¼šç”» Loss æ›²çº¿ ---
    plot_loss_curve(train_loss_history, val_loss_history)

    # --- è®­ç»ƒç»“æŸåï¼šåŠ è½½æœ€ä½³æ¨¡å‹å¹¶å¯è§†åŒ–é¢„æµ‹æ•ˆæœ ---
    print("ğŸ”„ Loading best model for visualization...")
    model.load_state_dict(torch.load(MODEL_SAVE_PATH))
    plot_validation_results(model, val_loader, device)


if __name__ == "__main__":
    train()
