import xarray as xr
import pandas as pd
import numpy as np
import os
import glob
from GPTPV.utils.config import load_config

config_file = "../config/config.yaml"
config = load_config(config_file)

# --- é…ç½®ä¿®æ”¹ ---
# 1. è¿™é‡Œç°åœ¨æŒ‡å‘åŒ…å« nc æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„
ERA5_DIR = config["file_paths"]["era5_dir"]
OUTPUT_CSV = config["file_paths"]["era5_output"]
REAL_STATIONS = config["stations"]["real_stations"]
POINTS_PER_STATION = config["stations"]["virtual_points_per_station"]

# 2. è·å–æ—¶é—´èŒƒå›´
START_DATE = pd.to_datetime(config["dates"]["start_date"])
# ç»™ç»“æŸæ—¥æœŸåŠ ä¸Š 23å°æ—¶59åˆ†59ç§’ï¼Œç¡®ä¿è¦†ç›–ä¸€æ•´å¤©
END_DATE = pd.to_datetime(config["dates"]["end_date"]) + pd.Timedelta(hours=23, minutes=59, seconds=59)


def get_needed_year_months(start_dt, end_dt):
    """è¿”å› (year, month) çš„åˆ—è¡¨ï¼ŒåŒ…å« start åˆ° end æ¶‰åŠçš„æ‰€æœ‰æœˆä»½"""
    result = []
    curr = start_dt
    while curr <= end_dt:
        result.append(curr.strftime("%Y_%m"))
        # ç§»åŠ¨åˆ°ä¸‹ä¸ªæœˆç¬¬ä¸€å¤©
        if curr.month == 12:
            curr = pd.Timestamp(year=curr.year + 1, month=1, day=1)
        else:
            curr = pd.Timestamp(year=curr.year, month=curr.month + 1, day=1)

    # å»é‡ï¼ˆè™½ä»¥ä¸Šé€»è¾‘ä¸ä¼šé‡å¤ï¼Œä½†ä¸ºäº†ä¿é™©ï¼‰å¹¶è¿”å›
    return sorted(list(set(result)))


# ===========================================

def get_relevant_era5_files(data_dir, start_date, end_date):
    """
    æ ¹æ®å¼€å§‹å’Œç»“æŸæ—¥æœŸï¼Œç­›é€‰å‡ºéœ€è¦è¯»å–çš„ .nc æ–‡ä»¶åˆ—è¡¨ã€‚
    æ–‡ä»¶åæ ¼å¼å‡è®¾ä¸º: era5_shanxi_YYYY_MM.nc
    """
    all_files = sorted(glob.glob(os.path.join(data_dir, "era5_shanxi_*.nc")))
    selected_files = []

    # ç”Ÿæˆæˆ‘ä»¬éœ€è¦è¦†ç›–çš„å¹´æœˆåˆ—è¡¨ (ä¾‹å¦‚: 2020-01, 2020-02)
    # ä½¿ç”¨ 'MS' (Month Start) é¢‘ç‡ç”Ÿæˆ
    needed_periods = get_needed_year_months(start_date, end_date)

    # å¦‚æœæ—¶é—´èŒƒå›´åœ¨ä¸€ä¸ªæœˆå†… (ä¾‹å¦‚ 1æœˆ5æ—¥åˆ°1æœˆ10æ—¥)ï¼Œdate_rangeå¯èƒ½ä¸ºç©ºï¼Œæ‰‹åŠ¨è¡¥ä¸Š
    if len(needed_periods) == 0:
        needed_periods = [start_date.strftime("%Y_%m")]
        # å¦‚æœè·¨æœˆä½†æ²¡æ»¡ä¸€ä¸ªæœˆ(ä¾‹å¦‚1æœˆ31åˆ°2æœˆ1æ—¥)ï¼Œéœ€è¦æŠŠç»“æŸæœˆä¹ŸåŠ ä¸Š
        if start_date.strftime("%Y_%m") != end_date.strftime("%Y_%m"):
            needed_periods.append(end_date.strftime("%Y_%m"))

    print(f"ğŸ“… éœ€è¦å¯»æ‰¾çš„æœˆä»½: {list(needed_periods)}")

    for f_path in all_files:
        f_name = os.path.basename(f_path)
        # ç®€å•ç²—æš´åŒ¹é…ï¼šåªè¦æ–‡ä»¶ååŒ…å« "2020_01" è¿™ç§å­—ç¬¦ä¸²å°±é€‰ä¸­
        for period in needed_periods:
            if period in f_name:
                selected_files.append(f_path)
                break

    return sorted(selected_files)


def extract_and_broadcast_era5():
    # 1. ç­›é€‰æ–‡ä»¶
    relevant_files = get_relevant_era5_files(ERA5_DIR, START_DATE, END_DATE)

    if not relevant_files:
        print(f"âŒ åœ¨ {ERA5_DIR} ä¸‹æœªæ‰¾åˆ°åŒ¹é… {START_DATE} åˆ° {END_DATE} çš„æ–‡ä»¶ï¼")
        return

    print(f"ğŸ“‚ å°†åŠ è½½ä»¥ä¸‹ {len(relevant_files)} ä¸ªæ–‡ä»¶:")
    for f in relevant_files:
        print(f"   - {os.path.basename(f)}")

    # 2. ä½¿ç”¨ open_mfdataset åŒæ—¶æ‰“å¼€å¤šä¸ªæ–‡ä»¶å¹¶è‡ªåŠ¨åˆå¹¶æ—¶é—´ç»´åº¦
    print("ğŸ”„ æ­£åœ¨åŠ è½½å¹¶åˆå¹¶æ•°æ®é›†...")
    # chunkså‚æ•°æœ‰åŠ©äºå¤„ç†å¤§æ–‡ä»¶ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    try:
        ds = xr.open_mfdataset(relevant_files, combine='by_coords', chunks={'time': 500})
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return

    # 3. æ ‡å‡†åŒ–æ—¶é—´åˆ—å (é˜²æ­¢æœ‰çš„æ–‡ä»¶å« valid_time æœ‰çš„å« time)
    if 'valid_time' in ds.coords:
        ds = ds.rename({'valid_time': 'time'})

    # 4. ğŸ¯ æ ¸å¿ƒæ­¥éª¤ï¼šæ—¶é—´åˆ‡ç‰‡ (Time Slicing)
    # è¿™ä¸€æ­¥åªä¿ç•™ config ä¸­é…ç½®çš„æ—¶é—´æ®µ
    print(f"âœ‚ï¸ æ­£åœ¨è£åˆ‡æ—¶é—´èŒƒå›´: {START_DATE} -> {END_DATE}")
    try:
        ds_sliced = ds.sel(time=slice(START_DATE, END_DATE))
    except Exception as e:
        print(f"âŒ æ—¶é—´è£åˆ‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ncæ–‡ä»¶å†…çš„æ—¶é—´æ ¼å¼ã€‚é”™è¯¯: {e}")
        return

    if ds_sliced.time.size == 0:
        print("âš ï¸ è£åˆ‡åæ•°æ®ä¸ºç©ºï¼è¯·æ£€æŸ¥ Start/End Date æ˜¯å¦åœ¨æ–‡ä»¶çš„æ—¶é—´èŒƒå›´å†…ã€‚")
        return

    # 5. æ—¶é—´é‡é‡‡æ ·ä¸æ’å€¼ (1h -> 15min) [ä¿ç•™ä¹‹å‰çš„æ ¸å¿ƒé€»è¾‘]
    print("â³ æ­£åœ¨æ‰§è¡Œ 15åˆ†é’Ÿ é¢‘ç‡çš„æ’å€¼å¤„ç†...")
    ds_15min = ds_sliced.resample(time='15min').interpolate('linear')

    # 6. æ‰‹åŠ¨æ„é€ æœ€å 3 ä¸ªæ—¶é—´ç‚¹ (23:15, 23:30, 23:45)
    # è·å–æœ€åä¸€ä¸ªæ—¶é—´ç‚¹ (23:00) çš„æ•°æ®
    last_frame = ds_15min.isel(time=-1)

    # ç”Ÿæˆéœ€è¦è¡¥å……çš„æ—¶é—´æˆ³
    last_time = ds_15min.time.values[-1]
    tail_times = pd.date_range(start=last_time + pd.Timedelta(minutes=15), periods=3, freq='15min')

    # 7. åˆ›å»ºå°¾éƒ¨æ•°æ® (å¤åˆ¶ 23:00 çš„å€¼)
    # æˆ‘ä»¬é€šè¿‡éå† timestampsï¼ŒæŠŠ last_frame èµ‹äºˆæ–°çš„æ—¶é—´åæ ‡
    tail_list = []
    for t in tail_times:
        # å¤åˆ¶æ•°æ®ï¼Œå¹¶æ‰©å±•ç»´åº¦èµ‹äºˆæ–°çš„æ—¶é—´
        # expand_dims é…åˆ assign_coords æ˜¯ xarray æ ‡å‡†å¢åŠ æ—¶é—´æ­¥çš„æ–¹æ³•
        new_frame = last_frame.expand_dims(time=1).assign_coords(time=[t])
        tail_list.append(new_frame)

    # 8. æ‹¼æ¥ (Concat)
    # å°† åŸæœ¬çš„æ•°æ® + 3ä¸ªæ–°çš„å°¾å·´ æ‹¼èµ·æ¥
    ds_final = xr.concat([ds_15min] + tail_list, dim='time')

    # å°†å˜é‡åæŒ‡å› ds_15min ä»¥ä¾¿åç»­ä»£ç ä¸ç”¨æ”¹
    ds_15min = ds_final

    # 9. ç‰©ç†é‡è®¡ç®—
    print("ğŸ§® æ­£åœ¨è¿›è¡Œç‰©ç†é‡è®¡ç®—...")
    temp_c = ds_15min['t2m'] - 273.15
    precip_mm = ds_15min['tp'] * 1000
    precip_mm = precip_mm.where(precip_mm >= 0, 0)
    wind_speed = np.sqrt(ds_15min['u10'] ** 2 + ds_15min['v10'] ** 2)

    print("ğŸ“¥ æ­£åœ¨å°†è®¡ç®—ç»“æœåŠ è½½è‡³å†…å­˜ (Persisting data)...")
    # load() ä¼šå¼ºåˆ¶è§¦å‘è®¡ç®—å¹¶æŠŠç»“æœå­˜å…¥å†…å­˜ï¼Œä¹‹åçš„ .sel å°±ä¼šæ˜¯æ¯«ç§’çº§çš„çº¯å†…å­˜æ“ä½œ
    # å¦‚æœæ²¡æœ‰è¿™æ­¥ï¼Œåˆ™ä¼šåœ¨ .values å¤„è§¦å‘è®¡ç®—
    temp_c = temp_c.load()
    precip_mm = precip_mm.load()
    wind_speed = wind_speed.load()

    # 10. æå–ä¸å¹¿æ’­
    # ä¸ºäº†é¿å…å†…å­˜æº¢å‡ºï¼Œå¦‚æœæ•°æ®é‡ç‰¹åˆ«å¤§ï¼Œè¿™é‡Œå¯ä»¥è€ƒè™‘å…ˆ load() è¿›å†…å­˜
    # æˆ–è€…ç›´æ¥è¿›è¡Œè®¡ç®— (xarray æ˜¯æ‡’åŠ è½½çš„)
    print("ğŸš€ æ­£åœ¨æå–å¹¶åˆ†å‘æ•°æ®...")

    # ç¡®ä¿æ—¶é—´ç´¢å¼•æ˜¯ pandas datetime
    time_index = pd.to_datetime(ds_15min.time.values)
    data_dict = {"Timestamp": time_index}

    for station in REAL_STATIONS:
        s_name = station['name']
        s_lat = station['lat']
        s_lon = station['lon']

        # æå–
        t_val = temp_c.sel(latitude=s_lat, longitude=s_lon, method='nearest').values
        p_val = precip_mm.sel(latitude=s_lat, longitude=s_lon, method='nearest').values
        w_val = wind_speed.sel(latitude=s_lat, longitude=s_lon, method='nearest').values

        for i in range(POINTS_PER_STATION):
            base_col = f"{s_name}_P{i}"
            data_dict[f"{base_col}_Temp"] = t_val
            data_dict[f"{base_col}_Wind"] = w_val
            data_dict[f"{base_col}_Precip"] = p_val

    # 8. ä¿å­˜
    final_df = pd.DataFrame(data_dict)
    final_df = final_df.set_index("Timestamp")

    print(f"===== ğŸ“Š æ•°æ®é¢„è§ˆ (æ—¶é—´èŒƒå›´: {final_df.index.min()} åˆ° {final_df.index.max()}) =====")
    print(final_df.iloc[-10:, :3].head())

    final_df.to_csv(OUTPUT_CSV, header=True)
    print(f"\nâœ… å¤„ç†å®Œæˆï¼å·²ä¿å­˜è‡³: {OUTPUT_CSV}")


if __name__ == "__main__":
    extract_and_broadcast_era5()
