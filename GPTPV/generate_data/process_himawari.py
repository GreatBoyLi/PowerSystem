import xarray as xr
import numpy as np
import pandas as pd
import os
import glob
from tqdm import tqdm
from GPTPV.utils.config import load_config

config_file = "../config/config.yaml"
config = load_config(config_file)

DATA_DIR = config["file_paths"]["himawari_dir"]

# 2. æ¨¡æ‹Ÿè®ºæ–‡ä¸­çš„ "5ä¸ªçœŸå®ç”µç«™" åæ ‡ (ä»¥å±±è¥¿å¤ªåŸ 37.8, 112.5 ä¸ºä¸­å¿ƒ)
# æˆ‘ä»¬åœ¨ä¸­å¿ƒé™„è¿‘éšæœºæ•£å¸ƒ 5 ä¸ªç‚¹
REAL_STATIONS = config["stations"]["real_stations"]

# 3. æ¯ä¸ªç”µç«™é€‰å¤šå°‘ä¸ªè™šæ‹Ÿç‚¹ï¼Ÿ (è®ºæ–‡è¯´5ä¸ªç«™å…±100ä¸ªç‚¹ -> æ¯ä¸ªç«™20ä¸ª)
POINTS_PER_STATION = config["stations"]["virtual_points_per_station"]

# 4. è¦å¤„ç†çš„æ—¥æœŸèŒƒå›´
START_DATE = config["dates"]["start_date"]
END_DATE = config["dates"]["end_date"]  # å…ˆè¯•è·‘ä¸€å¤©


# ===========================================

def get_spatial_indices(sample_file):
    """
    åªè¿è¡Œä¸€æ¬¡ï¼šè®¡ç®— "å“ªäº›åƒç´ ç‚¹" æ˜¯æˆ‘ä»¬éœ€è¦æå–çš„ã€‚
    è¿”å›ä¸€ä¸ªåˆ—è¡¨ï¼ŒåŒ…å« 100 ä¸ª (lat_idx, lon_idx) åæ ‡å¯¹ã€‚
    """
    print(f"ğŸŒ æ­£åœ¨è®¡ç®—ç©ºé—´ç´¢å¼•ï¼Œä½¿ç”¨æ¨¡æ¿æ–‡ä»¶: {sample_file}")
    ds = xr.open_dataset(sample_file)

    # è·å–ç»çº¬åº¦ç½‘æ ¼
    # æ³¨æ„ï¼šHimawariæ•°æ®çš„ lat å¯èƒ½æ˜¯ä»å¤§åˆ°å°æ’åˆ—çš„ï¼Œlon æ˜¯ä»å°åˆ°å¤§
    lats = ds['latitude'].values
    lons = ds['longitude'].values

    # ç”Ÿæˆç½‘æ ¼åæ ‡çŸ©é˜µ (ç”¨äºè®¡ç®—è·ç¦»)
    # è¿™æ­¥å¯èƒ½ä¼šæ¶ˆè€—ä¸€ç‚¹å†…å­˜ï¼Œä½†åœ¨ 5km ç²¾åº¦ä¸‹å®Œå…¨æ²¡é—®é¢˜
    lon_grid, lat_grid = np.meshgrid(lons, lats)

    all_selected_indices = []

    for station in REAL_STATIONS:
        # è®¡ç®—è¯¥ç”µç«™åˆ°æ‰€æœ‰åƒç´ ç‚¹çš„è·ç¦»å¹³æ–¹ (æ¬§æ°è·ç¦»è¿‘ä¼¼)
        dist_sq = (lat_grid - station['lat']) ** 2 + (lon_grid - station['lon']) ** 2

        # æ‰¾åˆ°è·ç¦»æœ€è¿‘çš„ N ä¸ªç‚¹çš„æ‰å¹³ç´¢å¼• (flat index)
        # argpartition æ¯” argsort å¿«ï¼Œåªæ‰¾å‡ºå‰ N ä¸ªï¼Œä¸ä¸¥æ ¼æ’åº
        flat_indices = np.argpartition(dist_sq.ravel(), POINTS_PER_STATION)[:POINTS_PER_STATION]

        # å°†æ‰å¹³ç´¢å¼•è½¬å› (y, x) äºŒç»´ç´¢å¼•
        # unravel_index ä¼šè¿”å› (lat_indices, lon_indices)
        y_indices, x_indices = np.unravel_index(flat_indices, dist_sq.shape)

        # å­˜èµ·æ¥
        for y, x in zip(y_indices, x_indices):
            all_selected_indices.append({
                "station": station['name'],
                "lat_val": lats[y],
                "lon_val": lons[x],
                "lat_idx": y,
                "lon_idx": x
            })

    print(f"âœ… ç©ºé—´é€‰ç‚¹å®Œæˆï¼å…±é€‰ä¸­ {len(all_selected_indices)} ä¸ªè™šæ‹Ÿç«™ç‚¹ã€‚")
    return all_selected_indices


def process_temporal_data(target_indices, date_list):
    """
    éå†æ¯ä¸€å¤©ã€æ¯ä¸ªæ–‡ä»¶ï¼Œæå– SWR æ•°æ®
    """
    results = []  # å­˜æ”¾æœ€ç»ˆæ•°æ®

    for current_date in date_list:
        date_str = current_date.strftime("%Y-%m-%d")
        yyyy = current_date.strftime("%Y")
        mm = current_date.strftime("%m")
        dd = current_date.strftime("%d")

        print(f"\nğŸ“… æ­£åœ¨æå–æ•°æ®: {date_str}")

        # éå† 24 å°æ—¶ x 6 ä¸ªæ—¶åˆ» (00, 10, 20, 30, 40, 50)
        # è®ºæ–‡è¦æ±‚çš„é€»è¾‘ï¼š
        # 00 -> 00
        # 10 -> æ‰”æ‰
        # 20 -> 15 (Mapping)
        # 30 -> 30
        # 40 -> æ‰”æ‰
        # 50 -> 45 (Mapping)

        # æˆ‘ä»¬å…ˆåªå…³å¿ƒæˆ‘ä»¬éœ€è¦çš„æ—¶é—´ç‚¹: 00, 20, 30, 50
        # å¯¹åº”çš„ç›®æ ‡åˆ†é’Ÿ: 00, 15, 30, 45
        time_mapping = {
            "00": "00",
            "20": "15",
            "30": "30",
            "50": "45"
        }

        for hour in tqdm(range(24), desc="Hour Loop"):  # éå†å°æ—¶
            hh = f"{hour:02d}"
            hour_dir = os.path.join(DATA_DIR, f"{yyyy}{mm}", dd, hh)

            if not os.path.exists(hour_dir):
                continue

            # è·å–è¯¥å°æ—¶ä¸‹çš„æ‰€æœ‰ .nc æ–‡ä»¶
            files = sorted(os.listdir(hour_dir))

            for f_name in files:
                if not f_name.endswith(".nc") or "02401_02401" not in f_name:
                    continue

                # è§£ææ–‡ä»¶åä¸­çš„åˆ†é’Ÿ (H08_..._0420_...)
                # æ–‡ä»¶åæ ¼å¼: H08_20200101_0420_...
                # åˆ†é’Ÿåœ¨ç¬¬ 3 æ®µ (index 2) çš„åä¸¤ä½
                try:
                    time_part = f_name.split("_")[2]  # "0420"
                    minute_str = time_part[2:]  # "20"
                except:
                    continue

                # æŒ‰ç…§è®ºæ–‡è§„åˆ™ç­›é€‰ï¼šåªè¦ 00, 20, 30, 50
                if minute_str not in time_mapping:
                    continue

                target_minute = time_mapping[minute_str]  # è½¬æ¢æˆ 00, 15, 30, 45

                # æ‰“å¼€æ–‡ä»¶æå–æ•°æ®
                full_path = os.path.join(hour_dir, f_name)
                try:
                    ds = xr.open_dataset(full_path)
                    swr_data = ds['SWR'].values  # è¯»å–æ•´ä¸ªçŸ©é˜µ (ä¸ºäº†é€Ÿåº¦ï¼Œä¸€æ¬¡è¯»å…¥å†…å­˜)
                    # æ³¨æ„ï¼šæœ‰äº›æ–‡ä»¶é‡ŒSWRå¯èƒ½æœ‰ scale_factorï¼Œxarrayä¼šè‡ªåŠ¨å¤„ç†

                    # æ„é€ è¿™ä¸€è¡Œæ•°æ®çš„æ—¶é—´æˆ³
                    timestamp = pd.Timestamp(f"{date_str} {hh}:{target_minute}:00")

                    row_data = {"Timestamp": timestamp}

                    # å¾ªç¯æå–é‚£ 100 ä¸ªç‚¹çš„å€¼
                    for i, idx_info in enumerate(target_indices):
                        val = swr_data[idx_info['lat_idx'], idx_info['lon_idx']]
                        # å¤„ç† NaN å’Œ è´Ÿå€¼ (å¤œé—´)
                        if np.isnan(val) or val < 0:
                            val = 0.0

                        # å‘½ååˆ—å: Station_1_Point_0
                        col_name = f"{idx_info['station']}_P{i % POINTS_PER_STATION}"
                        row_data[col_name] = val

                    results.append(row_data)
                    ds.close()

                except Exception as e:
                    print(f"è¯»å–é”™è¯¯ {f_name}: {e}")

    return pd.DataFrame(results)


def main():
    # 1. æ‰¾ä¸€ä¸ªå­˜åœ¨çš„ .nc æ–‡ä»¶åšæ¨¡æ¿ï¼Œè®¡ç®—ç©ºé—´ç´¢å¼•
    # è‡ªåŠ¨æœç´¢ç›®å½•ä¸‹ç¬¬ä¸€ä¸ªç¬¦åˆæ¡ä»¶çš„æ–‡ä»¶
    sample_files = glob.glob(f"{DATA_DIR}/*/*/*/*.nc")
    if not sample_files:
        print("âŒ ç›®å½•ä¸‹æ²¡æœ‰æ‰¾åˆ°ä»»ä½• .nc æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        return

    # æ‰¾ä¸€ä¸ª 5km çš„æ–‡ä»¶
    valid_sample = None
    for f in sample_files:
        if "02401_02401" in f:
            valid_sample = f
            break

    if not valid_sample:
        print("âŒ æ²¡æ‰¾åˆ° 02401_02401 è§„æ ¼çš„æ–‡ä»¶ï¼")
        return

    # 2. è®¡ç®—ç©ºé—´ç´¢å¼• (è¿™ä¸€æ­¥åªåšä¸€æ¬¡)
    spatial_indices = get_spatial_indices(valid_sample)

    # 3. å¤„ç†æ—¶é—´åºåˆ—
    dates = pd.date_range(START_DATE, END_DATE)
    df = process_temporal_data(spatial_indices, dates)

    # 4. æ’åºå’Œå»é‡
    if not df.empty:
        df = df.sort_values("Timestamp").set_index("Timestamp")

        # 5. å¡«è¡¥ç¼ºå¤±å€¼ (è®ºæ–‡è§„åˆ™ï¼šmissing value filled with next moment)
        # ffillæ˜¯å‘å‰å¡«ï¼Œbfillæ˜¯å‘å(next moment)å¡«
        df = df.bfill()

        print("\n===== æ•°æ®é¢„è§ˆ =====")
        print(df.head())

        output_file = "virtual_pv_data_shanxi.csv"
        df.to_csv(output_file)
        print(f"\nâœ… å¤„ç†å®Œæˆï¼æ•°æ®å·²ä¿å­˜è‡³: {output_file}")
    else:
        print("âš ï¸ æ²¡æœ‰æå–åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ—¥æœŸèŒƒå›´æˆ–æ–‡ä»¶åã€‚")


if __name__ == "__main__":
    main()
