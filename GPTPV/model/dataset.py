import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from GPTPV.utils.config import load_config


class PVForecastDataset(Dataset):
    def __init__(self, csv_file, input_len=112, output_len=16, mode='train', train_ratio=0.8):
        """
        å‚æ•°:
        - csv_file: åˆšæ‰ç”Ÿæˆçš„ normalized power csv è·¯å¾„
        - input_len: è¾“å…¥åºåˆ—é•¿åº¦ (è®ºæ–‡å– 112) [cite: 377]
        - output_len: é¢„æµ‹åºåˆ—é•¿åº¦ (è®ºæ–‡å– 16)
        - mode: 'train' æˆ– 'val' (åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†)
        """
        self.input_len = input_len
        self.output_len = output_len

        # 1. è¯»å–æ•°æ®
        print(f"ğŸ“‚ Loading dataset from {csv_file}...")
        df = pd.read_csv(csv_file, index_col=0, parse_dates=True)

        # 2. æå–æ—¶é—´æˆ³ç‰¹å¾ (ç”¨äº Time Embedding)
        # è®ºæ–‡å…¬å¼ (6): T_k = [e_d, e_w, e_m, e_y]
        # æˆ‘ä»¬é¢„å…ˆè®¡ç®—å¥½æ‰€æœ‰æ—¶é—´æ­¥çš„ç‰¹å¾
        timestamps = df.index

        # Day of Year (å½’ä¸€åŒ–åˆ° -0.5 ~ 0.5)
        day_of_year = timestamps.dayofyear.values
        e_y = (day_of_year - 1) / 365.0 - 0.5

        # Day of Month
        day_of_month = timestamps.day.values
        e_m = (day_of_month - 1) / 30.0 - 0.5

        # Day of Week
        day_of_week = timestamps.dayofweek.values
        e_w = (day_of_week) / 6.0 - 0.5

        # Hour of Day (æ³¨æ„ï¼šæ•°æ®æ˜¯15miné—´éš”ï¼Œè®ºæ–‡å…¬å¼æ˜¯ Hour number)
        # è¿™é‡Œæˆ‘ä»¬ç”¨ (hour + minute/60) ç²¾åº¦æ›´é«˜ï¼Œæˆ–è€…ä¸¥æ ¼æŒ‰è®ºæ–‡åªå– hour
        hour_of_day = timestamps.hour.values
        e_d = (hour_of_day) / 23.0 - 0.5

        # æ‹¼æ¥æ—¶é—´ç‰¹å¾: (Time_Steps, 4)
        self.time_features = np.stack([e_d, e_w, e_m, e_y], axis=1).astype(np.float32)

        # 3. å¤„ç†åŠŸç‡æ•°æ® (Time_Steps, Num_Stations)
        self.data = df.values.astype(np.float32)

        # 4. ç”Ÿæˆæ»‘çª—ç´¢å¼• (Samples)
        # å¹¶ä¸æ˜¯ç®€å•çš„åˆ‡ç‰‡ï¼Œå› ä¸ºæˆ‘ä»¬æœ‰ 100 ä¸ªç«™ç‚¹ã€‚
        # æˆ‘ä»¬æŠŠæ‰€æœ‰ç«™ç‚¹çš„æ•°æ®è§†ä¸ºâ€œç‹¬ç«‹çš„æ ·æœ¬â€ï¼Œä½†åœ¨æ—¶é—´è½´ä¸Šæ»‘åŠ¨ã€‚
        # æ€»æ ·æœ¬æ•° = (æ—¶é—´æ­¥æ•° - window_size + 1) * ç«™ç‚¹æ•°

        n_timestamps, n_stations = self.data.shape
        total_window = input_len + output_len

        # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›† (æŒ‰æ—¶é—´åˆ‡åˆ†)
        split_idx = int(n_timestamps * train_ratio)

        self.samples = []

        if mode == 'train':
            # éå†æ—¶é—´è½´ (ç›´åˆ° split_idx)
            for t in range(split_idx - total_window):
                # éå†æ‰€æœ‰ç«™ç‚¹
                for s in range(n_stations):
                    self.samples.append((t, s))
        else:
            # éªŒè¯é›†
            for t in range(split_idx, n_timestamps - total_window):
                for s in range(n_stations):
                    self.samples.append((t, s))

        print(f"âœ… {mode.upper()} Dataset created. Total samples: {len(self.samples)}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        # è·å–å½“å‰æ ·æœ¬çš„èµ·å§‹æ—¶é—´å’Œç«™ç‚¹ç´¢å¼•
        start_t, station_idx = self.samples[idx]

        # 1. åˆ‡åˆ†æ—¶é—´çª—å£
        mid_t = start_t + self.input_len
        end_t = mid_t + self.output_len

        # 2. è·å–åŠŸç‡æ•°æ® (Power Value)
        # Input: [0, 112]
        x_seq = self.data[start_t: mid_t, station_idx]
        # Target: [112, 128]
        y_seq = self.data[mid_t: end_t, station_idx]

        # 3. è·å–æ—¶é—´ç‰¹å¾ (Time Embedding Input)
        # æ³¨æ„ï¼šTransformer éœ€è¦çŸ¥é“ Input å’Œ Output å¯¹åº”çš„æ—¶é—´
        x_time = self.time_features[start_t: mid_t, :]  # Encoder ç”¨çš„æ—¶é—´
        y_time = self.time_features[mid_t: end_t, :]  # Decoder ç”¨çš„æ—¶é—´

        # 4. æ‰©å±•ç»´åº¦ä»¥é€‚é…æ¨¡å‹è¾“å…¥ (seq_len, 1) -> å› ä¸ºæ˜¯å•å˜é‡
        return {
            "x_seq": torch.tensor(x_seq).unsqueeze(-1),  # Encoder Input (112, 1)
            "y_seq": torch.tensor(y_seq).unsqueeze(-1),  # Target (16, 1)
            "x_time": torch.tensor(x_time),  # Encoder Time (112, 4)
            "y_time": torch.tensor(y_time)  # Decoder Time (16, 4)
        }


# --- æµ‹è¯•ä»£ç  ---
if __name__ == "__main__":
    config_file = "../config/config.yaml"
    config = load_config(config_file)
    # å‡è®¾ä½ çš„ CSV è·¯å¾„
    csv_path = config["file_paths"]["output_power_csv"]

    # åˆ›å»º Dataset
    train_ds = PVForecastDataset(csv_path, mode='train')

    # åˆ›å»º DataLoader
    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)

    # å–ä¸€ä¸ª Batch çœ‹çœ‹é•¿ä»€ä¹ˆæ ·
    batch = next(iter(train_loader))
    print("\nğŸ“¦ Batch Data Shapes:")
    print(f"Encoder Input (Power): {batch['x_seq'].shape}")  # é¢„æœŸ: [32, 112, 1]
    print(f"Target Output (Power): {batch['y_seq'].shape}")  # é¢„æœŸ: [32, 16, 1]
    print(f"Encoder Time Feats:    {batch['x_time'].shape}")  # é¢„æœŸ: [32, 112, 4]